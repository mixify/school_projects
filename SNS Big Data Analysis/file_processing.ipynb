{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tarfile\n",
    "import pickle\n",
    "import data_processing_twitter as dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_path = 'TwitterSampled2/'\n",
    "tar_list = glob.glob(crawled_path+'*.tar') # get tar file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TwitterSampled2/Twitter_201401.tar',\n",
       " 'TwitterSampled2/Twitter_201402.tar',\n",
       " 'TwitterSampled2/Twitter_201403.tar',\n",
       " 'TwitterSampled2/Twitter_201404.tar',\n",
       " 'TwitterSampled2/Twitter_201405.tar',\n",
       " 'TwitterSampled2/Twitter_201406.tar',\n",
       " 'TwitterSampled2/Twitter_201407.tar',\n",
       " 'TwitterSampled2/Twitter_201408.tar',\n",
       " 'TwitterSampled2/Twitter_201409.tar',\n",
       " 'TwitterSampled2/Twitter_201410.tar',\n",
       " 'TwitterSampled2/Twitter_201411.tar',\n",
       " 'TwitterSampled2/Twitter_201412.tar',\n",
       " 'TwitterSampled2/Twitter_201501.tar',\n",
       " 'TwitterSampled2/Twitter_201502.tar',\n",
       " 'TwitterSampled2/Twitter_201503.tar',\n",
       " 'TwitterSampled2/Twitter_201504.tar',\n",
       " 'TwitterSampled2/Twitter_201505.tar',\n",
       " 'TwitterSampled2/Twitter_201506.tar',\n",
       " 'TwitterSampled2/Twitter_201507.tar',\n",
       " 'TwitterSampled2/Twitter_201508.tar',\n",
       " 'TwitterSampled2/Twitter_201509.tar',\n",
       " 'TwitterSampled2/Twitter_201510.tar',\n",
       " 'TwitterSampled2/Twitter_201511.tar',\n",
       " 'TwitterSampled2/Twitter_201512.tar']"
      ]
     },
     "execution_count": 2291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tarfile(tarpath): # extract and get tarfile's file names\n",
    "    tar_file = tarfile.open(tarpath)\n",
    "    tar_file.extractall()\n",
    "    names = [tarinfo.name for tarinfo in tar_file]\n",
    "    tar_file.close()\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_targzfile(targztext): # extract targz file\n",
    "    targz_file = tarfile.open(targztext)\n",
    "    targz_file.extractall()\n",
    "    targz_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data,data_path): # save keyword data\n",
    "    with open(data_path,'wb') as f:\n",
    "        pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path): # load keyword data\n",
    "    with open(data_path,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception on ./20140125160000-20140125170000.txt\n",
      "exception on ./20140125150000-20140125160000.txt\n",
      "exception on ./20140125180000-20140125190000.txt\n",
      "exception on ./20140125190000-20140125200000.txt\n",
      "exception on ./20140124190000-20140124200000.txt\n",
      "exception on ./20140127110000-20140127120000.txt\n",
      "exception on ./20140101050000-20140101060000.txt\n",
      "exception on ./20140129010000-20140129020000.txt\n",
      "exception on ./20140101210000-20140101220000.txt\n",
      "exception on ./20140123170000-20140123180000.txt\n",
      "exception on ./20140114120000-20140114130000.txt\n",
      "exception on ./20140124120000-20140124130000.txt\n",
      "exception on ./20140107090000-20140107100000.txt\n",
      "exception on ./20140113170000-20140113180000.txt\n",
      "exception on ./20140103170000-20140103180000.txt\n",
      "exception on ./20140112060000-20140112070000.txt\n",
      "exception on ./20140122210000-20140122220000.txt\n",
      "exception on ./20140117090000-20140117100000.txt\n",
      "exception on ./20140104100000-20140104110000.txt\n",
      "exception on ./20140122040000-20140122050000.txt\n",
      "exception on ./20140104150000-20140104160000.txt\n",
      "exception on ./20140122010000-20140122020000.txt\n",
      "exception on ./20140131080000-20140131090000.txt\n",
      "exception on ./20140120130000-20140120140000.txt\n",
      "exception on ./20140114150000-20140114160000.txt\n",
      "exception on ./20140121080000-20140121090000.txt\n",
      "exception on ./20140130130000-20140130140000.txt\n",
      "exception on ./20140114100000-20140114110000.txt\n",
      "exception on ./20140112010000-20140112020000.txt\n",
      "exception on ./20140101080000-20140101090000.txt\n",
      "exception on ./20140110130000-20140110140000.txt\n",
      "exception on ./20140112040000-20140112050000.txt\n",
      "exception on ./20140124100000-20140124110000.txt\n",
      "exception on ./20140102040000-20140102050000.txt\n",
      "exception on ./20140124150000-20140124160000.txt\n",
      "exception on ./20140102010000-20140102020000.txt\n",
      "exception on ./20140111080000-20140111090000.txt\n",
      "exception on ./20140124160000-20140124170000.txt\n",
      "exception on ./20140102020000-20140102030000.txt\n",
      "exception on ./20140125070000-20140125080000.txt\n",
      "exception on ./20140122200000-20140122210000.txt\n",
      "exception on ./20140112020000-20140112030000.txt\n",
      "exception on ./20140105070000-20140105080000.txt\n",
      "exception on ./20140102200000-20140102210000.txt\n",
      "exception on ./20140114160000-20140114170000.txt\n",
      "exception on ./20140104160000-20140104170000.txt\n",
      "exception on ./20140122020000-20140122030000.txt\n",
      "exception on ./20140115070000-20140115080000.txt\n",
      "exception on ./20140112200000-20140112210000.txt\n",
      "exception on ./20140112050000-20140112060000.txt\n",
      "exception on ./20140129080000-20140129090000.txt\n",
      "exception on ./20140127180000-20140127190000.txt\n",
      "exception on ./20140122220000-20140122230000.txt\n",
      "exception on ./20140112000000-20140112010000.txt\n",
      "exception on ./20140102000000-20140102010000.txt\n",
      "exception on ./20140124140000-20140124150000.txt\n",
      "exception on ./20140102050000-20140102060000.txt\n",
      "exception on ./20140124110000-20140124120000.txt\n",
      "exception on ./20140127190000-20140127200000.txt\n",
      "exception on ./20140128130000-20140128140000.txt\n",
      "exception on ./20140126030000-20140126040000.txt\n",
      "exception on ./20140122000000-20140122010000.txt\n",
      "exception on ./20140104140000-20140104150000.txt\n",
      "exception on ./20140119080000-20140119090000.txt\n",
      "exception on ./20140108130000-20140108140000.txt\n",
      "exception on ./20140122050000-20140122060000.txt\n",
      "exception on ./20140104110000-20140104120000.txt\n",
      "exception on ./20140107190000-20140107200000.txt\n",
      "exception on ./20140117180000-20140117190000.txt\n",
      "exception on ./20140106030000-20140106040000.txt\n",
      "exception on ./20140112220000-20140112230000.txt\n",
      "exception on ./20140109080000-20140109090000.txt\n",
      "exception on ./20140118130000-20140118140000.txt\n",
      "exception on ./20140114110000-20140114120000.txt\n",
      "exception on ./20140117190000-20140117200000.txt\n",
      "exception on ./20140107180000-20140107190000.txt\n",
      "exception on ./20140116030000-20140116040000.txt\n",
      "exception on ./20140102220000-20140102230000.txt\n",
      "exception on ./20140114140000-20140114150000.txt\n",
      "exception on ./20140119120000-20140119130000.txt\n",
      "exception on ./20140122230000-20140123000000.txt\n",
      "exception on ./20140131160000-20140131170000.txt\n",
      "exception on ./20140117020000-20140117030000.txt\n",
      "exception on ./20140127200000-20140127210000.txt\n",
      "exception on ./20140120070000-20140120080000.txt\n",
      "exception on ./20140130070000-20140130080000.txt\n",
      "exception on ./20140109120000-20140109130000.txt\n",
      "exception on ./20140107020000-20140107030000.txt\n",
      "exception on ./20140121160000-20140121170000.txt\n",
      "exception on ./20140117200000-20140117210000.txt\n",
      "exception on ./20140110070000-20140110080000.txt\n",
      "exception on ./20140129120000-20140129130000.txt\n",
      "exception on ./20140112230000-20140113000000.txt\n",
      "exception on ./20140127020000-20140127030000.txt\n",
      "exception on ./20140101160000-20140101170000.txt\n",
      "exception on ./20140102230000-20140103000000.txt\n",
      "exception on ./20140111160000-20140111170000.txt\n",
      "exception on ./20140107200000-20140107210000.txt\n",
      "exception on ./20140123030000-20140123040000.txt\n",
      "exception on ./20140109150000-20140109160000.txt\n",
      "exception on ./20140122190000-20140122200000.txt\n",
      "exception on ./20140121110000-20140121120000.txt\n",
      "exception on ./20140107050000-20140107060000.txt\n",
      "exception on ./20140109100000-20140109110000.txt\n",
      "exception on ./20140121140000-20140121150000.txt\n",
      "exception on ./20140107000000-20140107010000.txt\n",
      "exception on ./20140119100000-20140119110000.txt\n",
      "exception on ./20140117000000-20140117010000.txt\n",
      "exception on ./20140131140000-20140131150000.txt\n",
      "exception on ./20140127220000-20140127230000.txt\n",
      "exception on ./20140122180000-20140122190000.txt\n",
      "exception on ./20140119150000-20140119160000.txt\n",
      "exception on ./20140117050000-20140117060000.txt\n",
      "exception on ./20140131110000-20140131120000.txt\n",
      "exception on ./20140111140000-20140111150000.txt\n",
      "exception on ./20140107220000-20140107230000.txt\n",
      "exception on ./20140113030000-20140113040000.txt\n",
      "exception on ./20140102180000-20140102190000.txt\n",
      "exception on ./20140112190000-20140112200000.txt\n",
      "exception on ./20140111110000-20140111120000.txt\n",
      "exception on ./20140117220000-20140117230000.txt\n",
      "exception on ./20140103030000-20140103040000.txt\n",
      "exception on ./20140112180000-20140112190000.txt\n",
      "exception on ./20140102190000-20140102200000.txt\n",
      "exception on ./20140101110000-20140101120000.txt\n",
      "exception on ./20140127050000-20140127060000.txt\n",
      "exception on ./20140129100000-20140129110000.txt\n",
      "exception on ./20140101140000-20140101150000.txt\n",
      "exception on ./20140127000000-20140127010000.txt\n",
      "exception on ./20140117210000-20140117220000.txt\n",
      "exception on ./20140129160000-20140129170000.txt\n",
      "exception on ./20140122090000-20140122100000.txt\n",
      "exception on ./20140101120000-20140101130000.txt\n",
      "exception on ./20140127060000-20140127070000.txt\n",
      "exception on ./20140107210000-20140107220000.txt\n",
      "exception on ./20140111120000-20140111130000.txt\n",
      "exception on ./20140128070000-20140128080000.txt\n",
      "exception on ./20140126170000-20140126180000.txt\n",
      "exception on ./20140119160000-20140119170000.txt\n",
      "exception on ./20140112090000-20140112100000.txt\n",
      "exception on ./20140127210000-20140127220000.txt\n",
      "exception on ./20140117060000-20140117070000.txt\n",
      "exception on ./20140131120000-20140131130000.txt\n",
      "exception on ./20140108070000-20140108080000.txt\n",
      "exception on ./20140106170000-20140106180000.txt\n",
      "exception on ./20140118070000-20140118080000.txt\n",
      "exception on ./20140116170000-20140116180000.txt\n",
      "exception on ./20140109160000-20140109170000.txt\n",
      "exception on ./20140102090000-20140102100000.txt\n",
      "exception on ./20140121120000-20140121130000.txt\n",
      "exception on ./20140107060000-20140107070000.txt\n",
      "exception on ./20140111100000-20140111110000.txt\n",
      "exception on ./20140124080000-20140124090000.txt\n",
      "exception on ./20140111150000-20140111160000.txt\n",
      "exception on ./20140125130000-20140125140000.txt\n",
      "exception on ./20140129110000-20140129120000.txt\n",
      "exception on ./20140127010000-20140127020000.txt\n",
      "exception on ./20140101150000-20140101160000.txt\n",
      "exception on ./20140129140000-20140129150000.txt\n",
      "exception on ./20140127040000-20140127050000.txt\n",
      "exception on ./20140101100000-20140101110000.txt\n",
      "exception on ./20140109110000-20140109120000.txt\n",
      "exception on ./20140105130000-20140105140000.txt\n",
      "exception on ./20140114080000-20140114090000.txt\n",
      "exception on ./20140107010000-20140107020000.txt\n",
      "exception on ./20140121150000-20140121160000.txt\n",
      "exception on ./20140109140000-20140109150000.txt\n",
      "exception on ./20140107040000-20140107050000.txt\n",
      "exception on ./20140121100000-20140121110000.txt\n",
      "exception on ./20140119140000-20140119150000.txt\n",
      "exception on ./20140131100000-20140131110000.txt\n",
      "exception on ./20140117040000-20140117050000.txt\n",
      "exception on ./20140119110000-20140119120000.txt\n",
      "exception on ./20140115130000-20140115140000.txt\n",
      "exception on ./20140104080000-20140104090000.txt\n",
      "exception on ./20140131150000-20140131160000.txt\n",
      "exception on ./20140117010000-20140117020000.txt\n",
      "exception on ./20140114040000-20140114050000.txt\n",
      "exception on ./20140119190000-20140119200000.txt\n",
      "exception on ./20140107080000-20140107090000.txt\n",
      "exception on ./20140116130000-20140116140000.txt\n",
      "exception on ./20140114010000-20140114020000.txt\n",
      "exception on ./20140109180000-20140109190000.txt\n",
      "exception on ./20140118030000-20140118040000.txt\n",
      "exception on ./20140109190000-20140109200000.txt\n",
      "exception on ./20140117080000-20140117090000.txt\n",
      "exception on ./20140106130000-20140106140000.txt\n",
      "exception on ./20140122150000-20140122160000.txt\n",
      "exception on ./20140104010000-20140104020000.txt\n",
      "exception on ./20140119180000-20140119190000.txt\n",
      "exception on ./20140108030000-20140108040000.txt\n",
      "exception on ./20140122100000-20140122110000.txt\n",
      "exception on ./20140104040000-20140104050000.txt\n",
      "exception on ./20140126130000-20140126140000.txt\n",
      "exception on ./20140129190000-20140129200000.txt\n",
      "exception on ./20140128030000-20140128040000.txt\n",
      "exception on ./20140102150000-20140102160000.txt\n",
      "exception on ./20140124010000-20140124020000.txt\n",
      "exception on ./20140102100000-20140102110000.txt\n",
      "exception on ./20140124040000-20140124050000.txt\n",
      "exception on ./20140112100000-20140112110000.txt\n",
      "exception on ./20140127080000-20140127090000.txt\n",
      "exception on ./20140129180000-20140129190000.txt\n",
      "exception on ./20140112150000-20140112160000.txt\n",
      "exception on ./20140115170000-20140115180000.txt\n",
      "exception on ./20140101090000-20140101100000.txt\n",
      "exception on ./20140104060000-20140104070000.txt\n",
      "exception on ./20140122120000-20140122130000.txt\n",
      "exception on ./20140111090000-20140111100000.txt\n",
      "exception on ./20140124210000-20140124220000.txt\n",
      "exception on ./20140114060000-20140114070000.txt\n",
      "exception on ./20140105170000-20140105180000.txt\n",
      "exception on ./20140104210000-20140104220000.txt\n",
      "exception on ./20140131090000-20140131100000.txt\n",
      "exception on ./20140112120000-20140112130000.txt\n",
      "exception on ./20140125170000-20140125180000.txt\n",
      "exception on ./20140114210000-20140114220000.txt\n",
      "exception on ./20140121090000-20140121100000.txt\n",
      "exception on ./20140124060000-20140124070000.txt\n",
      "exception on ./20140102120000-20140102130000.txt\n",
      "exception on ./20140111180000-20140111190000.txt\n",
      "exception on ./20140114220000-20140114230000.txt\n",
      "exception on ./20140124050000-20140124060000.txt\n",
      "exception on ./20140102110000-20140102120000.txt\n",
      "exception on ./20140101190000-20140101200000.txt\n",
      "exception on ./20140124000000-20140124010000.txt\n",
      "exception on ./20140102140000-20140102150000.txt\n",
      "exception on ./20140112140000-20140112150000.txt\n",
      "exception on ./20140101180000-20140101190000.txt\n",
      "exception on ./20140110030000-20140110040000.txt\n",
      "exception on ./20140104220000-20140104230000.txt\n",
      "exception on ./20140112110000-20140112120000.txt\n",
      "exception on ./20140111190000-20140111200000.txt\n",
      "exception on ./20140114000000-20140114010000.txt\n",
      "exception on ./20140121180000-20140121190000.txt\n",
      "exception on ./20140124220000-20140124230000.txt\n",
      "exception on ./20140130030000-20140130040000.txt\n",
      "exception on ./20140131190000-20140131200000.txt\n",
      "exception on ./20140114050000-20140114060000.txt\n",
      "exception on ./20140131180000-20140131190000.txt\n",
      "exception on ./20140120030000-20140120040000.txt\n",
      "exception on ./20140104050000-20140104060000.txt\n",
      "exception on ./20140122110000-20140122120000.txt\n",
      "exception on ./20140121190000-20140121200000.txt\n",
      "exception on ./20140104000000-20140104010000.txt\n",
      "exception on ./20140122140000-20140122150000.txt\n",
      "exception on ./20140119090000-20140119100000.txt\n",
      "exception on ./20140112160000-20140112170000.txt\n",
      "exception on ./20140104200000-20140104210000.txt\n",
      "exception on ./20140103070000-20140103080000.txt\n",
      "exception on ./20140114200000-20140114210000.txt\n",
      "exception on ./20140113070000-20140113080000.txt\n",
      "exception on ./20140109090000-20140109100000.txt\n",
      "exception on ./20140102160000-20140102170000.txt\n",
      "exception on ./20140124020000-20140124030000.txt\n",
      "exception on ./20140129090000-20140129100000.txt\n",
      "exception on ./20140122160000-20140122170000.txt\n",
      "exception on ./20140104020000-20140104030000.txt\n",
      "exception on ./20140114020000-20140114030000.txt\n",
      "exception on ./20140124200000-20140124210000.txt\n",
      "exception on ./20140123070000-20140123080000.txt\n",
      "exception on ./20140112070000-20140112080000.txt\n",
      "exception on ./20140107230000-20140108000000.txt\n",
      "exception on ./20140115200000-20140115210000.txt\n",
      "exception on ./20140110230000-20140111000000.txt\n",
      "exception on ./20140125020000-20140125030000.txt\n",
      "exception on ./20140103160000-20140103170000.txt\n",
      "exception on ./20140108090000-20140108100000.txt\n",
      "exception on ./20140113160000-20140113170000.txt\n",
      "exception on ./20140118090000-20140118100000.txt\n",
      "exception on ./20140102070000-20140102080000.txt\n",
      "exception on ./20140105200000-20140105210000.txt\n",
      "exception on ./20140117230000-20140118000000.txt\n",
      "exception on ./20140120230000-20140121000000.txt\n",
      "exception on ./20140115020000-20140115030000.txt\n",
      "exception on ./20140122070000-20140122080000.txt\n",
      "exception on ./20140125200000-20140125210000.txt\n",
      "exception on ./20140127230000-20140128000000.txt\n",
      "exception on ./20140130230000-20140131000000.txt\n",
      "exception on ./20140105020000-20140105030000.txt\n",
      "exception on ./20140123160000-20140123170000.txt\n",
      "exception on ./20140128090000-20140128100000.txt\n",
      "exception on ./20140113140000-20140113150000.txt\n",
      "exception on ./20140110190000-20140110200000.txt\n",
      "exception on ./20140113110000-20140113120000.txt\n",
      "exception on ./20140105220000-20140105230000.txt\n",
      "exception on ./20140111030000-20140111040000.txt\n",
      "exception on ./20140103110000-20140103120000.txt\n",
      "exception on ./20140125050000-20140125060000.txt\n",
      "exception on ./20140115220000-20140115230000.txt\n",
      "exception on ./20140101030000-20140101040000.txt\n",
      "exception on ./20140110180000-20140110190000.txt\n",
      "exception on ./20140103140000-20140103150000.txt\n",
      "exception on ./20140125000000-20140125010000.txt\n",
      "exception on ./20140120190000-20140120200000.txt\n",
      "exception on ./20140123110000-20140123120000.txt\n",
      "exception on ./20140105050000-20140105060000.txt\n",
      "exception on ./20140121030000-20140121040000.txt\n",
      "exception on ./20140130180000-20140130190000.txt\n",
      "exception on ./20140123140000-20140123150000.txt\n",
      "exception on ./20140105000000-20140105010000.txt\n",
      "exception on ./20140115000000-20140115010000.txt\n",
      "exception on ./20140115050000-20140115060000.txt\n",
      "exception on ./20140130190000-20140130200000.txt\n",
      "exception on ./20140131030000-20140131040000.txt\n",
      "exception on ./20140125220000-20140125230000.txt\n",
      "exception on ./20140120180000-20140120190000.txt\n",
      "exception on ./20140115060000-20140115070000.txt\n",
      "exception on ./20140108230000-20140109000000.txt\n",
      "exception on ./20140125230000-20140126000000.txt\n",
      "exception on ./20140125210000-20140125220000.txt\n",
      "exception on ./20140110090000-20140110100000.txt\n",
      "exception on ./20140104170000-20140104180000.txt\n",
      "exception on ./20140114170000-20140114180000.txt\n",
      "exception on ./20140123120000-20140123130000.txt\n",
      "exception on ./20140105060000-20140105070000.txt\n",
      "exception on ./20140123230000-20140124000000.txt\n",
      "exception on ./20140118230000-20140119000000.txt\n",
      "exception on ./20140103120000-20140103130000.txt\n",
      "exception on ./20140125060000-20140125070000.txt\n",
      "exception on ./20140103230000-20140104000000.txt\n",
      "exception on ./20140120090000-20140120100000.txt\n",
      "exception on ./20140115230000-20140116000000.txt\n",
      "exception on ./20140115210000-20140115220000.txt\n",
      "exception on ./20140113120000-20140113130000.txt\n",
      "exception on ./20140113230000-20140114000000.txt\n",
      "exception on ./20140128230000-20140129000000.txt\n",
      "exception on ./20140130090000-20140130100000.txt\n",
      "exception on ./20140105230000-20140106000000.txt\n",
      "exception on ./20140105210000-20140105220000.txt\n",
      "exception on ./20140124170000-20140124180000.txt\n",
      "exception on ./20140109030000-20140109040000.txt\n",
      "exception on ./20140109230000-20140110000000.txt\n",
      "exception on ./20140118180000-20140118190000.txt\n",
      "exception on ./20140105010000-20140105020000.txt\n",
      "exception on ./20140123150000-20140123160000.txt\n",
      "exception on ./20140107130000-20140107140000.txt\n",
      "exception on ./20140116080000-20140116090000.txt\n",
      "exception on ./20140108190000-20140108200000.txt\n",
      "exception on ./20140105040000-20140105050000.txt\n",
      "exception on ./20140123100000-20140123110000.txt\n",
      "exception on ./20140115040000-20140115050000.txt\n",
      "exception on ./20140119030000-20140119040000.txt\n",
      "exception on ./20140108180000-20140108190000.txt\n",
      "exception on ./20140115010000-20140115020000.txt\n",
      "exception on ./20140117130000-20140117140000.txt\n",
      "exception on ./20140106080000-20140106090000.txt\n",
      "exception on ./20140118190000-20140118200000.txt\n",
      "exception on ./20140113100000-20140113110000.txt\n",
      "exception on ./20140113150000-20140113160000.txt\n",
      "exception on ./20140128180000-20140128190000.txt\n",
      "exception on ./20140126080000-20140126090000.txt\n",
      "exception on ./20140125010000-20140125020000.txt\n",
      "exception on ./20140103150000-20140103160000.txt\n",
      "exception on ./20140129230000-20140130000000.txt\n",
      "exception on ./20140129030000-20140129040000.txt\n",
      "exception on ./20140128190000-20140128200000.txt\n",
      "exception on ./20140127130000-20140127140000.txt\n",
      "exception on ./20140125040000-20140125050000.txt\n",
      "exception on ./20140103100000-20140103110000.txt\n",
      "exception on ./20140126010000-20140126020000.txt\n",
      "exception on ./20140128110000-20140128120000.txt\n",
      "exception on ./20140124130000-20140124140000.txt\n",
      "exception on ./20140126040000-20140126050000.txt\n",
      "exception on ./20140128140000-20140128150000.txt\n",
      "exception on ./20140110100000-20140110110000.txt\n",
      "exception on ./20140110150000-20140110160000.txt\n",
      "exception on ./20140125080000-20140125090000.txt\n",
      "exception on ./20140116040000-20140116050000.txt\n",
      "exception on ./20140130100000-20140130110000.txt\n",
      "exception on ./20140118140000-20140118150000.txt\n",
      "exception on ./20140116010000-20140116020000.txt\n",
      "exception on ./20140130150000-20140130160000.txt\n",
      "exception on ./20140105080000-20140105090000.txt\n",
      "exception on ./20140114130000-20140114140000.txt\n",
      "exception on ./20140118110000-20140118120000.txt\n",
      "exception on ./20140120150000-20140120160000.txt\n",
      "exception on ./20140106010000-20140106020000.txt\n",
      "exception on ./20140115080000-20140115090000.txt\n",
      "exception on ./20140104130000-20140104140000.txt\n",
      "exception on ./20140108110000-20140108120000.txt\n",
      "exception on ./20140120100000-20140120110000.txt\n",
      "exception on ./20140106040000-20140106050000.txt\n",
      "exception on ./20140108140000-20140108150000.txt\n",
      "exception on ./20140110120000-20140110130000.txt\n",
      "exception on ./20140106210000-20140106220000.txt\n",
      "exception on ./20140127170000-20140127180000.txt\n",
      "exception on ./20140131230000-20140201000000.txt\n",
      "exception on ./20140129070000-20140129080000.txt\n",
      "exception on ./20140126060000-20140126070000.txt\n",
      "exception on ./20140123090000-20140123100000.txt\n",
      "exception on ./20140128160000-20140128170000.txt\n",
      "exception on ./20140116210000-20140116220000.txt\n",
      "exception on ./20140117170000-20140117180000.txt\n",
      "exception on ./20140119070000-20140119080000.txt\n",
      "exception on ./20140106060000-20140106070000.txt\n",
      "exception on ./20140120120000-20140120130000.txt\n",
      "exception on ./20140103090000-20140103100000.txt\n",
      "exception on ./20140108160000-20140108170000.txt\n",
      "exception on ./20140130120000-20140130130000.txt\n",
      "exception on ./20140116060000-20140116070000.txt\n",
      "exception on ./20140126210000-20140126220000.txt\n",
      "exception on ./20140113090000-20140113100000.txt\n",
      "exception on ./20140118160000-20140118170000.txt\n",
      "exception on ./20140107170000-20140107180000.txt\n",
      "exception on ./20140109070000-20140109080000.txt\n",
      "exception on ./20140130140000-20140130150000.txt\n",
      "exception on ./20140116000000-20140116010000.txt\n",
      "exception on ./20140118100000-20140118110000.txt\n",
      "exception on ./20140130110000-20140130120000.txt\n",
      "exception on ./20140116050000-20140116060000.txt\n",
      "exception on ./20140118150000-20140118160000.txt\n",
      "exception on ./20140123180000-20140123190000.txt\n",
      "exception on ./20140126220000-20140126230000.txt\n",
      "exception on ./20140106050000-20140106060000.txt\n",
      "exception on ./20140120110000-20140120120000.txt\n",
      "exception on ./20140123190000-20140123200000.txt\n",
      "exception on ./20140108150000-20140108160000.txt\n",
      "exception on ./20140122030000-20140122040000.txt\n",
      "exception on ./20140106000000-20140106010000.txt\n",
      "exception on ./20140120140000-20140120150000.txt\n",
      "exception on ./20140108100000-20140108110000.txt\n",
      "exception on ./20140126050000-20140126060000.txt\n",
      "exception on ./20140103190000-20140103200000.txt\n",
      "exception on ./20140113180000-20140113190000.txt\n",
      "exception on ./20140102030000-20140102040000.txt\n",
      "exception on ./20140116220000-20140116230000.txt\n",
      "exception on ./20140128150000-20140128160000.txt\n",
      "exception on ./20140126000000-20140126010000.txt\n",
      "exception on ./20140128100000-20140128110000.txt\n",
      "exception on ./20140110140000-20140110150000.txt\n",
      "exception on ./20140110110000-20140110120000.txt\n",
      "exception on ./20140113190000-20140113200000.txt\n",
      "exception on ./20140103180000-20140103190000.txt\n",
      "exception on ./20140112030000-20140112040000.txt\n",
      "exception on ./20140106220000-20140106230000.txt\n",
      "exception on ./20140131070000-20140131080000.txt\n",
      "exception on ./20140120160000-20140120170000.txt\n",
      "exception on ./20140106020000-20140106030000.txt\n",
      "exception on ./20140108120000-20140108130000.txt\n",
      "exception on ./20140116020000-20140116030000.txt\n",
      "exception on ./20140130160000-20140130170000.txt\n",
      "exception on ./20140118120000-20140118130000.txt\n",
      "exception on ./20140121070000-20140121080000.txt\n",
      "exception on ./20140126200000-20140126210000.txt\n",
      "exception on ./20140110160000-20140110170000.txt\n",
      "exception on ./20140101070000-20140101080000.txt\n",
      "exception on ./20140106200000-20140106210000.txt\n",
      "exception on ./20140111070000-20140111080000.txt\n",
      "exception on ./20140116200000-20140116210000.txt\n",
      "exception on ./20140126020000-20140126030000.txt\n",
      "exception on ./20140128120000-20140128130000.txt\n",
      "processed one tar file\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Twitter_201402/20140223130000-20140223140000.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-03231311e0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargz_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mhandle_targzfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./*.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1f590eb71b38>\u001b[0m in \u001b[0;36mhandle_targzfile\u001b[0;34m(targztext)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhandle_targzfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargztext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# extract targz file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtargz_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargztext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtargz_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtargz_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dqn/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1569\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dqn/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dqn/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Twitter_201402/20140223130000-20140223140000.tar.gz'"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for t in tar_list:\n",
    "    \n",
    "    names = handle_tarfile(t)\n",
    "    \n",
    "    dir_name = names[0]\n",
    "    targz_names = names[1:]\n",
    "    \n",
    "    for idx, tgz in enumerate(targz_names):\n",
    "        handle_targzfile(tgz)\n",
    "        \n",
    "    texts = glob.glob('./*.txt')\n",
    "        \n",
    "    for text_file in texts:\n",
    "        cnt+=1\n",
    "        if(cnt%10000 == 0):\n",
    "            print('processed 10000 files')\n",
    "        try:\n",
    "            corpus = dpt.pre_processing_data(text_file)\n",
    "\n",
    "            keyword_one = dpt.get_top_n_gram_words(corpus,10,1) # pure keyword\n",
    "            keyword_two = dpt.get_top_n_gram_words(corpus,10,2) # bigram\n",
    "            keyword_three = dpt.get_top_n_gram_words(corpus,10,3) # trigram\n",
    "\n",
    "            save_name_one = dir_name+text_file.replace('txt','pkl1')[1:]\n",
    "            save_name_two = dir_name+text_file.replace('txt','pkl2')[1:]\n",
    "            save_name_three = dir_name+text_file.replace('txt','pkl3')[1:]\n",
    "\n",
    "\n",
    "            save_data(keyword_one,save_name_one)\n",
    "            save_data(keyword_two,save_name_two)\n",
    "            save_data(keyword_three,save_name_three)\n",
    "\n",
    "            os.remove(text_file)\n",
    "        except:\n",
    "            print('exception on ' + text_file)\n",
    "        \n",
    "    for tgz in targz_names:\n",
    "        os.remove(tgz)\n",
    "        \n",
    "    print('processed one tar file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickles_with_size(n):\n",
    "    pickles1 = glob.glob('Twitter_201401/*.pkl'+str(n))\n",
    "    pickles2 = glob.glob('Twitter_201402/*.pkl'+str(n))\n",
    "    pickles3 = glob.glob('Twitter_201403/*.pkl'+str(n))\n",
    "    pickles4 = glob.glob('Twitter_201404/*.pkl'+str(n))\n",
    "\n",
    "    pickles = pickles1 + pickles2 + pickles3 + pickles4\n",
    "    sorted_plks = sorted(pickles)\n",
    "    plks = []\n",
    "    for plk in sorted_plks:\n",
    "        with open(plk,'rb') as f:\n",
    "            f=pickle.load(f)\n",
    "            plks.append(f)\n",
    "    return sorted_plks, plks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "plname_1, plk_1 = get_pickles_with_size(1)\n",
    "plname_2, plk_2 = get_pickles_with_size(2)\n",
    "plname_3, plk_3 = get_pickles_with_size(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('추억 사진 발견', 27),\n",
       " ('사진 발견 어디', 27),\n",
       " ('발견 어디 사진', 27),\n",
       " ('어디 사진 대만', 27),\n",
       " ('사진 대만 상해', 27),\n",
       " ('대만 상해 북경', 27),\n",
       " ('상해 북경 홍콩', 27),\n",
       " ('일 미안 구만', 24),\n",
       " ('미안 구만 별일', 24),\n",
       " ('구만 별일 내', 24)]"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'아미 감사': 386,\n",
       " '요대 제전': 349,\n",
       " '감사 새해': 265,\n",
       " '가요 대제전': 249,\n",
       " '마지막 날': 220,\n",
       " '년 년': 215,\n",
       " '해피 뉴': 209,\n",
       " '올해 마지막': 200,\n",
       " '행복 일': 194,\n",
       " '날 아미': 193}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_plk = dict((x,y) for x,y in plks[1])\n",
    "dict_plk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'거': 651, '사람': 394, '말': 360, '생각': 330, '내': 290, '분': 241, '일': 232, '때': 230, '게': 208, '사랑': 184}\n",
      "{'우타 프리': 46, '김연아 선수': 43, '님 방': 40, '방 방': 40, '방 티비': 40, '티비 대': 40, '대 채널': 40, '채널 가지': 40, '가지 우타': 40, '프리 채널': 40}\n",
      "{'님 방 방': 40, '방 방 티비': 40, '방 티비 대': 40, '티비 대 채널': 40, '대 채널 가지': 40, '채널 가지 우타': 40, '가지 우타 프리': 40, '우타 프리 채널': 40, '프리 채널 축구': 40, '채널 축구 애니': 40}\n"
     ]
    }
   ],
   "source": [
    "dict_plks_1 = [dict((x,y) for x,y in plk) for plk in plk_1]\n",
    "dict_plks_2 = [dict((x,y) for x,y in plk) for plk in plk_2]\n",
    "dict_plks_3 = [dict((x,y) for x,y in plk) for plk in plk_3]\n",
    "print(dict_plks_1[1116])\n",
    "print(dict_plks_2[1116])\n",
    "print(dict_plks_3[1116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'년 일': 945, '일 년': 894, '행복 일': 888, '년 년': 792, '감사 사랑': 748, '일 행복': 677, '분 년': 667, '년 모습': 654, '해피 뉴': 649, '사랑 합': 647}\n",
      "{'아미 감사': 386, '요대 제전': 349, '감사 새해': 265, '가요 대제전': 249, '마지막 날': 220, '년 년': 215, '해피 뉴': 209, '올해 마지막': 200, '행복 일': 194, '날 아미': 193}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('행복 일', 1255),\n",
       " ('년 일', 945),\n",
       " ('일 년', 894),\n",
       " ('년 년', 792),\n",
       " ('감사 사랑', 748),\n",
       " ('요대 제전', 694),\n",
       " ('일 행복', 677),\n",
       " ('분 년', 667),\n",
       " ('년 모습', 654),\n",
       " ('해피 뉴', 649),\n",
       " ('사랑 합', 647),\n",
       " ('새해 올해', 590),\n",
       " ('올해 듯이', 539),\n",
       " ('사람 행복', 296),\n",
       " ('행복 건강', 287),\n",
       " ('내 사랑', 283),\n",
       " ('소녀 시대', 277),\n",
       " ('건강 일', 276),\n",
       " ('새해 내', 270)]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(dict_plks[0])\n",
    "A = Counter(dict_plks[0])\n",
    "print(dict_plks[1])\n",
    "B = Counter(dict_plks[2])\n",
    "(A + B).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = 6\n",
    "divided = len(dict_plks)\n",
    "val = divided // divider\n",
    "\n",
    "def group_plks(divider, plks, plname):\n",
    "    regularzed_plks = []\n",
    "    plnames = []\n",
    "    for i in range(val):\n",
    "        a = Counter(plks[6*i])\n",
    "        b = Counter(plks[6*i+1])\n",
    "        c = Counter(plks[6*i+2])\n",
    "        d = Counter(plks[6*i+3])\n",
    "        e = Counter(plks[6*i+4])\n",
    "        f = Counter(plks[6*i+5])\n",
    "\n",
    "        merged = a+b+c+d+e+f\n",
    "\n",
    "        \n",
    "        if(i==0):\n",
    "            print(a)\n",
    "            print(b)\n",
    "            print((a+b).most_common())\n",
    "        regularzed_plks.append(merged.most_common())\n",
    "        plnames.append(plname[6*i+2])\n",
    "        \n",
    "    return plnames, regularzed_plks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'새해': 15332, '년': 8410, '일': 4118, '사랑': 3515, '행복': 3334, '해': 2429, '감사': 2309, '올해': 2241, '오빠': 2162, '분': 2042})\n",
      "Counter({'새해': 5706, '년': 2307, '거': 1945, '일': 1279, '감사': 1201, '사랑': 1164, '행복': 1131, '올해': 1056, '오빠': 969, '해': 799})\n",
      "[('새해', 21038), ('년', 10717), ('일', 5397), ('사랑', 4679), ('행복', 4465), ('감사', 3510), ('올해', 3297), ('해', 3228), ('오빠', 3131), ('분', 2042), ('거', 1945)]\n",
      "Counter({'년 일': 945, '일 년': 894, '행복 일': 888, '년 년': 792, '감사 사랑': 748, '일 행복': 677, '분 년': 667, '년 모습': 654, '해피 뉴': 649, '사랑 합': 647})\n",
      "Counter({'아미 감사': 386, '요대 제전': 349, '감사 새해': 265, '가요 대제전': 249, '마지막 날': 220, '년 년': 215, '해피 뉴': 209, '올해 마지막': 200, '행복 일': 194, '날 아미': 193})\n",
      "[('행복 일', 1082), ('년 년', 1007), ('년 일', 945), ('일 년', 894), ('해피 뉴', 858), ('감사 사랑', 748), ('일 행복', 677), ('분 년', 667), ('년 모습', 654), ('사랑 합', 647), ('아미 감사', 386), ('요대 제전', 349), ('감사 새해', 265), ('가요 대제전', 249), ('마지막 날', 220), ('올해 마지막', 200), ('날 아미', 193)]\n",
      "Counter({'일 행복 일': 658, '행복 일 년': 651, '년 일 행복': 648, '분 년 일': 645, '일 년 모습': 637, '모습 감사 사랑': 637, '년 가족 지인': 636, '가족 지인 친구': 636, '지인 친구 분': 636, '친구 분 년': 636})\n",
      "Counter({'올해 마지막 날': 193, '마지막 날 아미': 193, '날 아미 감사': 193, '아미 감사 집': 193, '감사 집 응원': 193, '집 응원 아미': 193, '응원 아미 감사': 193, '아미 감사 새해': 193, '감사 새해 평생': 193, '새해 평생 가요': 193})\n",
      "[('일 행복 일', 658), ('행복 일 년', 651), ('년 일 행복', 648), ('분 년 일', 645), ('일 년 모습', 637), ('모습 감사 사랑', 637), ('년 가족 지인', 636), ('가족 지인 친구', 636), ('지인 친구 분', 636), ('친구 분 년', 636), ('올해 마지막 날', 193), ('마지막 날 아미', 193), ('날 아미 감사', 193), ('아미 감사 집', 193), ('감사 집 응원', 193), ('집 응원 아미', 193), ('응원 아미 감사', 193), ('아미 감사 새해', 193), ('감사 새해 평생', 193), ('새해 평생 가요', 193)]\n"
     ]
    }
   ],
   "source": [
    "grp_plname_1, grp_plk_1 = group_plks(6, dict_plks_1, plname_1)\n",
    "grp_plname_2, grp_plk_2 = group_plks(6, dict_plks_2, plname_2)\n",
    "grp_plname_3, grp_plk_3 = group_plks(6, dict_plks_3, plname_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2179,
   "metadata": {},
   "outputs": [],
   "source": [
    "remarkable_data = {}\n",
    "for text, gps in zip(grp_plname_1,grp_plk_2):\n",
    "    if(gps[:10][0][1] > 1500):\n",
    "        date = text[text.find('/')+1:text.find('-')]\n",
    "        date = date[:4]+'/'+date[4:6]+'/'+date[6:8]\n",
    "        data = []\n",
    "        for tps in gps:\n",
    "            if(tps[1]>1500):\n",
    "                if date in remarkable_data:\n",
    "                    remarkable_data[date].add(tps[0])\n",
    "                else:\n",
    "                    remarkable_data[date] = {tps[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014/01/01': {'행복 일'}, '2014/01/06': {'콘서트 규현', '동방신기 콘서트', '슈퍼주니어 콘서트', '연습 이유', '뮤지컬 연습', '이유 동방신기'}, '2014/01/13': {'육 대'}, '2014/01/20': {'눈길 조심'}, '2014/01/23': {'가요 대상', '서울 가요'}, '2014/02/01': {'첸 첸'}, '2014/02/13': {'번 번'}, '2014/02/17': {'부산 외대'}, '2014/02/21': {'김연아 선수'}, '2014/04/14': {'명품 샵'}, '2014/04/25': {'세월 호'}, '2014/04/26': {'세월 호'}, '2014/04/27': {'세월 호'}, '2014/04/28': {'세월 호'}, '2014/04/29': {'세월 호'}, '2014/04/30': {'세월 호'}}\n"
     ]
    }
   ],
   "source": [
    "print(remarkable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler(maxpage,query,sort, date):\n",
    "    \n",
    "    title_text = []\n",
    "    contents_text = []\n",
    "\n",
    "    ft = date.replace(\"/\",\"\")\n",
    "    page = 1\n",
    "    url = \"https://search.naver.com/search.naver?where=news&query=\" + query + \"&sort=\"+str(sort)+\"&ds=\" + date + \"&de=\" + date + \"&nso=so%3Ar%2Cp%3Afrom\" + ft + \"to\" + ft + \"%2Ca%3A&start=\" + str(page)\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    tags = soup.select('._sp_each_title')\n",
    "    for tag in tags:\n",
    "        title_text.append(tag.text)\n",
    "\n",
    "\n",
    "    contents_lists = soup.select('ul.type01 dl')\n",
    "    for contents_list in contents_lists:\n",
    "        contents_cleansing(contents_list,contents_text)\n",
    "\n",
    "    result = date, (' '.join(title_text) + ' '.join(contents_text)), len(title_text), query\n",
    "        \n",
    "    return result\n",
    "def contents_cleansing(contents, contents_text): \n",
    "    first_cleansing_contents = re.sub('<dl>.*?</a> </div> </dd> <dd>', '', str(contents)).strip() \n",
    "    second_cleansing_contents = re.sub('<ul class=\"relation_lst\">.*?</dd>', '', first_cleansing_contents).strip()\n",
    "    third_cleansing_contents = re.sub('<.+?>', '', second_cleansing_contents).strip() \n",
    "    contents_text.append(third_cleansing_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.naver.com/search.naver?where=news&query=행복 일&sort=0&ds=2014/01/01&de=2014/01/01&nso=so%3Ar%2Cp%3Afrom20140101to20140101%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=콘서트 규현&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=동방신기 콘서트&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=슈퍼주니어 콘서트&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=연습 이유&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=뮤지컬 연습&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=이유 동방신기&sort=0&ds=2014/01/06&de=2014/01/06&nso=so%3Ar%2Cp%3Afrom20140106to20140106%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=육 대&sort=0&ds=2014/01/13&de=2014/01/13&nso=so%3Ar%2Cp%3Afrom20140113to20140113%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=눈길 조심&sort=0&ds=2014/01/20&de=2014/01/20&nso=so%3Ar%2Cp%3Afrom20140120to20140120%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=가요 대상&sort=0&ds=2014/01/23&de=2014/01/23&nso=so%3Ar%2Cp%3Afrom20140123to20140123%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=서울 가요&sort=0&ds=2014/01/23&de=2014/01/23&nso=so%3Ar%2Cp%3Afrom20140123to20140123%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=첸 첸&sort=0&ds=2014/02/01&de=2014/02/01&nso=so%3Ar%2Cp%3Afrom20140201to20140201%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=번 번&sort=0&ds=2014/02/13&de=2014/02/13&nso=so%3Ar%2Cp%3Afrom20140213to20140213%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=부산 외대&sort=0&ds=2014/02/17&de=2014/02/17&nso=so%3Ar%2Cp%3Afrom20140217to20140217%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=김연아 선수&sort=0&ds=2014/02/21&de=2014/02/21&nso=so%3Ar%2Cp%3Afrom20140221to20140221%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=명품 샵&sort=0&ds=2014/04/14&de=2014/04/14&nso=so%3Ar%2Cp%3Afrom20140414to20140414%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/25&de=2014/04/25&nso=so%3Ar%2Cp%3Afrom20140425to20140425%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/26&de=2014/04/26&nso=so%3Ar%2Cp%3Afrom20140426to20140426%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/27&de=2014/04/27&nso=so%3Ar%2Cp%3Afrom20140427to20140427%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/28&de=2014/04/28&nso=so%3Ar%2Cp%3Afrom20140428to20140428%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/29&de=2014/04/29&nso=so%3Ar%2Cp%3Afrom20140429to20140429%2Ca%3A&start=1\n",
      "https://search.naver.com/search.naver?where=news&query=세월 호&sort=0&ds=2014/04/30&de=2014/04/30&nso=so%3Ar%2Cp%3Afrom20140430to20140430%2Ca%3A&start=1\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "df = pd.DataFrame()\n",
    "\n",
    "topics = []\n",
    "for date,keylist in remarkable_data.items():\n",
    "    for keyword in keylist:\n",
    "        result = crawler(1,keyword,0,date)\n",
    "        topics.append(result)\n",
    "#             df.append(result, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2014/01/06', '문화 소외계층에게 뮤지컬 관람 기회 제공 뮤지컬 데뷔한 소향 인터뷰 뮤지컬 \\'힐링하트\\' 시즌3 홍광선 \"사연 많은 역할 좋아\" <스타예감> 뮤지컬 샛별 정재은 [단독] 슈퍼주니어 이특, 6일 부친상 조부모상 한꺼번에 ‘충격’ 려욱 \"이특 부친상 소식 들은 지 얼마 안돼 양해 부탁\" 이특, 6일 부친·조부모상…\"교통사고死, 망연자실\" ‘슈퍼주니어’ 이특, 교통사고로 부친·조부모 잃어 [단독인터뷰①] 홍경민 \"결혼, 마음은 당장이라도 가고 싶어\" “박살나보지 않은 배우가 성장할 수 있겠나”뮤지컬 ‘비보이를 사랑한 발레리나’는 발레리나 연습실 거리에 힙합광장이 조성되면서 벌어지는 다툼과 사랑 이야기를 다룬 무언극으로 세계적으로도 널리 알려진 한국의 창작 뮤지컬이다. 이번 공연은 구로구가... [동아일보] \"뮤지컬을 해보자는 제안을 10년 동안 받았어요. 계속 거절하다 처음 선택한 작품이에요.\" 뮤지컬... \\'이게 연습의 힘이구나\\'하고 실감했죠.\" 상대 배우에 따라 감정이 조금씩 달라지고 비슷한 색채로 맞춰가는... 이번 뮤지컬 \\'힐링하트\\'의 \\'정미소\\'처럼 상처를 안고 있는 인물이 좋다. 무대 경험과 연습을 통해 극중 인물에게 얻는 것이 많다. 예전에는 관객들 앞에서 공연하는 것이 즐거웠다면 요즘은 이에 더해 스스로 캐릭터를... 제가 어떻게 연기하고 싶어하는지 아시니까, 연습하기 전에 먼저 노래와 연기를 보여 드리고 조언을 얻어요. 음악에 관해서는 전문가잖아요. 부모님이 음악을 전공하신 게 감사하죠.” 지난해 뮤지컬 &lt;몬테크리스토&gt;에서... 이특의 누나도 뮤지컬 연습을 하다 사고 소식을 듣고 곧장 병원으로 달려갔다. 고인의 빈소는 고대구로병원 장례식장 201호에 합동으로 마련됐다. 이 장례식장 관계자는 “고인 세 분의 합동 분향소가 오후 1시 30분께... 현재 군 복무 중인 이특은 이날 비보를 전해 듣고 곧바로 장례식장으로 향했으며, 이특의 누나도 뮤지컬 연습 도중에 사고 소식을 듣고 곧장 병원으로 달려갔다. 한편 합동 분향소는 서울 고대 구로병원 장례식장 201호에... 이특의 누나인 박인영 역시 뮤지컬 연습 도중 소식을 듣고 서둘러 병원으로 이동했다. 관계자는 \"아직 구체적인 사고경위 등은 알지 못한다\"면서 \"갑작스러운 사고에 유족 모두 참담한 비극에 경황이 없는 상태다. 추후... 이특의 누나도 뮤지컬 연습 도중 사고 소식을 듣고 곧장 병원으로 달려갔다. 빈소가 차려진 서울 구로구 고려대 구로병원 관계자는 “장례식장 201호실에 고인 세 분의 합동 분향소가 마련됐다”며 “상주는 돌아가신... 홍경민은 \"올해는 유난히 제가 뮤지컬 공연을 많이 하게 됐다\"면서 \"3월부터 연습해서 세 작품을 연달아 하게 됐는데, 뮤지컬 공연을 계속 1년 동안 했었기 때문에 거기에서 얻었던 에너지나 기쁨이 크다. 그 기분 잘... 연습 중간에 어디 계신다는 것도 모르고 있었는데 갑자기 일어서요. 그런데 ‘잘못 됐다’는 저의 순간적... 배우에겐 완성이란 게 없잖아요.” -그동안 뮤지컬 작품을 많이 해서 뮤지컬 배우란 칭호가 익숙하지만, 뮤지컬...', 10, '뮤지컬 연습')\n"
     ]
    }
   ],
   "source": [
    "print(topics[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrankr import TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이처럼 정성이 가득 담긴 성훈의 새해 인사는 새로운 한 해를 시작하는 시청자들의 안녕과 행복을 바라는.\n",
      "규현은 6일 자신의 트위터에 “뮤지컬 연습 가다가 급 이유없이 SMtown Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요 금요일은 또 온다”는 글과 함께 사진을 올렸다.\n",
      "슈퍼주니어 규현이 6일 자신의 트위터를 통해 “뮤지컬 연습 가다가 급 이유없이 SM town Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요 금요일은 또 온다”라는 메시지와 함께.\n",
      "이유가 무엇일까? 연습의 문제가 가장 큰 것 같다.\n",
      "이특의 누나도 뮤지컬 연습 도중 사고 소식을 듣고 곧장 병원으로 달려갔다.\n",
      "규현은 6일 오전 자신의 트위터에 “뮤지컬 연습 가다가 급 이유 없이 SMtown Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요.\n",
      "소녀시대 써니는 1월 20일 자신의 트위터에 \"눈이 와요..다들 눈길 조심!! 다치지마!!\"라는 글을 게재하며 눈길을 다니는 팬들을 걱정했다.\n",
      "'제23회 하이원 서울가요대상'(Seoul Music Awards) 시상식이 23일 오후 서울 잠실실내체육관에서 열렸다.\n",
      "'제23회 하이원 서울가요대상'(Seoul Music Awards) 시상식이 23일 오후 서울 잠실실내체육관에서 열렸다.\n",
      "부림사건 국보법도 무죄…\"국가 존립 위험성 없어\" 서세원 감독 4년만에 새 작품…이번엔 [이승만 일대기] 마사회 '마이동풍'… 주민들 집단반발 '부림사건' 33년 만에 무죄 판결, \"故노무현 변호사의 헌신 덕\" 수지, 별그대 카메오 출연 ‘김수현과 케미 폭발’ 대전 자동차 번호판 발급 수수료 인하될 전망 박겸수 강북구청장 ‘동 신년인사회’ 시작 푹 자도 피곤한 이유…'거북목 증후군'의 증상은? [픽스 스타리그] 김택용, 박성균 꺾고 승자전 진출 기아자동차 생산직 \"나이 무제한, 초봉 5000, 정년 보장\"ccho@yna.co.kr 2009년 부림사건 피해자 7명에 대한 재심에서 법원은 게엄법 위반과 집시번 위반에 대해서만 무죄 또는 면소 판결했다.\n",
      "경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰 '경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰' 경주 마우나리조트 강당이 붕괴하는 사고가 발생해 부산외대 학생 50~60명이 매몰된 것으로 알려졌다.\n",
      "박근혜 대통령은 21일 소치동계올림픽 피겨스케이팅 여자 싱글 종목에서 은메달을 딴 김연아 선수에게 축전을 보내 격려했다.\n",
      "송도 더샵 마스터뷰에서는 송도국제도시의 위상에 걸 맞은 명품문화공간을 만들어 나가기 위해 지역민들을 위한 다양한 행사들을 진행하고 있다.\n",
      "[세월호 침몰사고로 희생된 안산 단원고 학생 25명의 장례식이 25일 치러진다.\n",
      "세월호 침몰은 대한민국의 총체적 난맥상을 그대로 드러냈다.\n",
      "▲26일 오후2시 세월호 실종자 구조·수색작업을 진행하고 있는 바지선 언딘리베로 호(號).\n",
      "세월호와 달리 사흘 전 대서양에서 화재를 당한 스페인 여객선 선원들은 침착한 대응으로 승객 전원을 무사히 구출했습니다.\n",
      "[ ▲ 세월호 참사 14일째.\n",
      "▲ 세월호 실시간.\n"
     ]
    }
   ],
   "source": [
    "events = {}\n",
    "for topic in topics:\n",
    "    if(topic[2]>5):\n",
    "        date = topic[0]\n",
    "        textrank = TextRank(topic[1])\n",
    "        summ = textrank.summarize(1)\n",
    "        if topic[0] in events:\n",
    "            events[date].add(summ)\n",
    "        else:\n",
    "            events[date] = {summ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014/01/01': {'이처럼 정성이 가득 담긴 성훈의 새해 인사는 새로운 한 해를 시작하는 시청자들의 안녕과 행복을 바라는.'}, '2014/01/06': {'이특의 누나도 뮤지컬 연습 도중 사고 소식을 듣고 곧장 병원으로 달려갔다.', '이유가 무엇일까? 연습의 문제가 가장 큰 것 같다.', '규현은 6일 오전 자신의 트위터에 “뮤지컬 연습 가다가 급 이유 없이 SMtown Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요.', '슈퍼주니어 규현이 6일 자신의 트위터를 통해 “뮤지컬 연습 가다가 급 이유없이 SM town Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요 금요일은 또 온다”라는 메시지와 함께.', '규현은 6일 자신의 트위터에 “뮤지컬 연습 가다가 급 이유없이 SMtown Week 동방신기 콘서트에 간 규현과 슈퍼주니어 콘서트에 간 촹 투척~ 월요일이지만 힘내요 금요일은 또 온다”는 글과 함께 사진을 올렸다.'}, '2014/01/20': {'소녀시대 써니는 1월 20일 자신의 트위터에 \"눈이 와요..다들 눈길 조심!! 다치지마!!\"라는 글을 게재하며 눈길을 다니는 팬들을 걱정했다.'}, '2014/01/23': {\"'제23회 하이원 서울가요대상'(Seoul Music Awards) 시상식이 23일 오후 서울 잠실실내체육관에서 열렸다.\"}, '2014/02/13': {'부림사건 국보법도 무죄…\"국가 존립 위험성 없어\" 서세원 감독 4년만에 새 작품…이번엔 [이승만 일대기] 마사회 \\'마이동풍\\'… 주민들 집단반발 \\'부림사건\\' 33년 만에 무죄 판결, \"故노무현 변호사의 헌신 덕\" 수지, 별그대 카메오 출연 ‘김수현과 케미 폭발’ 대전 자동차 번호판 발급 수수료 인하될 전망 박겸수 강북구청장 ‘동 신년인사회’ 시작 푹 자도 피곤한 이유…\\'거북목 증후군\\'의 증상은? [픽스 스타리그] 김택용, 박성균 꺾고 승자전 진출 기아자동차 생산직 \"나이 무제한, 초봉 5000, 정년 보장\"ccho@yna.co.kr 2009년 부림사건 피해자 7명에 대한 재심에서 법원은 게엄법 위반과 집시번 위반에 대해서만 무죄 또는 면소 판결했다.'}, '2014/02/17': {\"경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰 '경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰' 경주 마우나리조트 강당이 붕괴하는 사고가 발생해 부산외대 학생 50~60명이 매몰된 것으로 알려졌다.\"}, '2014/02/21': {'박근혜 대통령은 21일 소치동계올림픽 피겨스케이팅 여자 싱글 종목에서 은메달을 딴 김연아 선수에게 축전을 보내 격려했다.'}, '2014/04/14': {'송도 더샵 마스터뷰에서는 송도국제도시의 위상에 걸 맞은 명품문화공간을 만들어 나가기 위해 지역민들을 위한 다양한 행사들을 진행하고 있다.'}, '2014/04/25': {'[세월호 침몰사고로 희생된 안산 단원고 학생 25명의 장례식이 25일 치러진다.'}, '2014/04/26': {'세월호 침몰은 대한민국의 총체적 난맥상을 그대로 드러냈다.'}, '2014/04/27': {'▲26일 오후2시 세월호 실종자 구조·수색작업을 진행하고 있는 바지선 언딘리베로 호(號).'}, '2014/04/28': {'세월호와 달리 사흘 전 대서양에서 화재를 당한 스페인 여객선 선원들은 침착한 대응으로 승객 전원을 무사히 구출했습니다.'}, '2014/04/29': {'[ ▲ 세월호 참사 14일째.'}, '2014/04/30': {'▲ 세월호 실시간.'}}\n"
     ]
    }
   ],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2273,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frame = pd.DataFrame.from_dict(events,orient='index').transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014/01/01</th>\n",
       "      <th>2014/01/06</th>\n",
       "      <th>2014/01/20</th>\n",
       "      <th>2014/01/23</th>\n",
       "      <th>2014/02/13</th>\n",
       "      <th>2014/02/17</th>\n",
       "      <th>2014/02/21</th>\n",
       "      <th>2014/04/14</th>\n",
       "      <th>2014/04/25</th>\n",
       "      <th>2014/04/26</th>\n",
       "      <th>2014/04/27</th>\n",
       "      <th>2014/04/28</th>\n",
       "      <th>2014/04/29</th>\n",
       "      <th>2014/04/30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이처럼 정성이 가득 담긴 성훈의 새해 인사는 새로운 한 해를 시작하는 시청자들의 안...</td>\n",
       "      <td>이특의 누나도 뮤지컬 연습 도중 사고 소식을 듣고 곧장 병원으로 달려갔다.</td>\n",
       "      <td>소녀시대 써니는 1월 20일 자신의 트위터에 \"눈이 와요..다들 눈길 조심!! 다치...</td>\n",
       "      <td>'제23회 하이원 서울가요대상'(Seoul Music Awards) 시상식이 23일...</td>\n",
       "      <td>부림사건 국보법도 무죄…\"국가 존립 위험성 없어\" 서세원 감독 4년만에 새 작품…이...</td>\n",
       "      <td>경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰 '경주 마우나리조트 붕괴…부...</td>\n",
       "      <td>박근혜 대통령은 21일 소치동계올림픽 피겨스케이팅 여자 싱글 종목에서 은메달을 딴 ...</td>\n",
       "      <td>송도 더샵 마스터뷰에서는 송도국제도시의 위상에 걸 맞은 명품문화공간을 만들어 나가기...</td>\n",
       "      <td>[세월호 침몰사고로 희생된 안산 단원고 학생 25명의 장례식이 25일 치러진다.</td>\n",
       "      <td>세월호 침몰은 대한민국의 총체적 난맥상을 그대로 드러냈다.</td>\n",
       "      <td>▲26일 오후2시 세월호 실종자 구조·수색작업을 진행하고 있는 바지선 언딘리베로 호...</td>\n",
       "      <td>세월호와 달리 사흘 전 대서양에서 화재를 당한 스페인 여객선 선원들은 침착한 대응으...</td>\n",
       "      <td>[ ▲ 세월호 참사 14일째.</td>\n",
       "      <td>▲ 세월호 실시간.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>이유가 무엇일까? 연습의 문제가 가장 큰 것 같다.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>규현은 6일 오전 자신의 트위터에 “뮤지컬 연습 가다가 급 이유 없이 SMtown ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>슈퍼주니어 규현이 6일 자신의 트위터를 통해 “뮤지컬 연습 가다가 급 이유없이 SM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>규현은 6일 자신의 트위터에 “뮤지컬 연습 가다가 급 이유없이 SMtown Week...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          2014/01/01  \\\n",
       "0  이처럼 정성이 가득 담긴 성훈의 새해 인사는 새로운 한 해를 시작하는 시청자들의 안...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/01/06  \\\n",
       "0          이특의 누나도 뮤지컬 연습 도중 사고 소식을 듣고 곧장 병원으로 달려갔다.   \n",
       "1                       이유가 무엇일까? 연습의 문제가 가장 큰 것 같다.   \n",
       "2  규현은 6일 오전 자신의 트위터에 “뮤지컬 연습 가다가 급 이유 없이 SMtown ...   \n",
       "3  슈퍼주니어 규현이 6일 자신의 트위터를 통해 “뮤지컬 연습 가다가 급 이유없이 SM...   \n",
       "4  규현은 6일 자신의 트위터에 “뮤지컬 연습 가다가 급 이유없이 SMtown Week...   \n",
       "\n",
       "                                          2014/01/20  \\\n",
       "0  소녀시대 써니는 1월 20일 자신의 트위터에 \"눈이 와요..다들 눈길 조심!! 다치...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/01/23  \\\n",
       "0  '제23회 하이원 서울가요대상'(Seoul Music Awards) 시상식이 23일...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/02/13  \\\n",
       "0  부림사건 국보법도 무죄…\"국가 존립 위험성 없어\" 서세원 감독 4년만에 새 작품…이...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/02/17  \\\n",
       "0  경주 마우나리조트 붕괴…부산외대 학생 50~60명 매몰 '경주 마우나리조트 붕괴…부...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/02/21  \\\n",
       "0  박근혜 대통령은 21일 소치동계올림픽 피겨스케이팅 여자 싱글 종목에서 은메달을 딴 ...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/04/14  \\\n",
       "0  송도 더샵 마스터뷰에서는 송도국제도시의 위상에 걸 맞은 명품문화공간을 만들어 나가기...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                     2014/04/25  \\\n",
       "0  [세월호 침몰사고로 희생된 안산 단원고 학생 25명의 장례식이 25일 치러진다.   \n",
       "1                                          None   \n",
       "2                                          None   \n",
       "3                                          None   \n",
       "4                                          None   \n",
       "\n",
       "                         2014/04/26  \\\n",
       "0  세월호 침몰은 대한민국의 총체적 난맥상을 그대로 드러냈다.   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "\n",
       "                                          2014/04/27  \\\n",
       "0  ▲26일 오후2시 세월호 실종자 구조·수색작업을 진행하고 있는 바지선 언딘리베로 호...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                          2014/04/28        2014/04/29  \\\n",
       "0  세월호와 달리 사흘 전 대서양에서 화재를 당한 스페인 여객선 선원들은 침착한 대응으...  [ ▲ 세월호 참사 14일째.   \n",
       "1                                               None              None   \n",
       "2                                               None              None   \n",
       "3                                               None              None   \n",
       "4                                               None              None   \n",
       "\n",
       "   2014/04/30  \n",
       "0  ▲ 세월호 실시간.  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  "
      ]
     },
     "execution_count": 2276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_frame.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
